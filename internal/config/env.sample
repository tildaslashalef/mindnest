# Mindnest sample environment configuration file
# Copy this file to .env and modify as needed

# Environment Configuration
# ENV_FILE_PATH=/path/to/env (optional - used to specify a custom .env file location)

# LLM Configuration
MINDNEST_LLM_DEFAULT_PROVIDER=claude # Options: ollama, calude, gemini
# Each provider has its own model configuration below

# Ollama Configuration
MINDNEST_OLLAMA_ENDPOINT=http://localhost:11434
MINDNEST_OLLAMA_TIMEOUT=120s
MINDNEST_OLLAMA_MAX_RETRIES=3
MINDNEST_OLLAMA_MODEL=gemma3
MINDNEST_OLLAMA_EMBEDDING_MODEL=nomic-embed-text
MINDNEST_OLLAMA_MAX_TOKENS=2048
MINDNEST_OLLAMA_TEMPERATURE=0.7
MINDNEST_OLLAMA_MAX_IDLE_CONNS=100
MINDNEST_OLLAMA_MAX_IDLE_CONNS_PER_HOST=100
MINDNEST_OLLAMA_IDLE_CONN_TIMEOUT=90s

# Claude Configuration
MINDNEST_CLAUDE_API_KEY=your_claude_api_key_here
MINDNEST_CLAUDE_BASE_URL=https://api.anthropic.com
MINDNEST_CLAUDE_MODEL=claude-3-7-sonnet-20250219
MINDNEST_CLAUDE_EMBEDDING_MODEL=ollama  # Set to "ollama" to use Ollama's embedding model instead
MINDNEST_CLAUDE_TIMEOUT=60s
MINDNEST_CLAUDE_MAX_RETRIES=3
MINDNEST_CLAUDE_MAX_TOKENS=4096
MINDNEST_CLAUDE_TEMPERATURE=0.1
MINDNEST_CLAUDE_TOP_P=0.9
MINDNEST_CLAUDE_TOP_K=40
MINDNEST_CLAUDE_API_VERSION=2023-06-01
# API beta features control
MINDNEST_CLAUDE_USE_API_BETA=false
# Only used if USE_API_BETA is true - comma-separated list of Claude API beta features
# MINDNEST_CLAUDE_API_BETA=feature1,feature2
MINDNEST_CLAUDE_USE_STOP_SEQUENCES=false
# MINDNEST_CLAUDE_STOP_SEQUENCES=  # Comma-separated list of stop sequences

# Gemini Configuration
MINDNEST_GEMINI_API_KEY=your_gemini_api_key_here
MINDNEST_GEMINI_BASE_URL=https://generativelanguage.googleapis.com
MINDNEST_GEMINI_API_VERSION=v1beta           # API version for chat models (v1 or v1beta)
MINDNEST_GEMINI_EMBEDDING_VERSION=v1beta     # API version for embedding models (v1 or v1beta)
MINDNEST_GEMINI_MODEL=gemini-2.5-pro-exp-03-25
MINDNEST_GEMINI_EMBEDDING_MODEL=gemini-embedding-exp-03-07  # Or set to "ollama" to use Ollama's embedding model instead
MINDNEST_GEMINI_TIMEOUT=60s
MINDNEST_GEMINI_MAX_RETRIES=3
MINDNEST_GEMINI_MAX_TOKENS=4096
MINDNEST_GEMINI_TEMPERATURE=0.1
MINDNEST_GEMINI_TOP_P=0.9
MINDNEST_GEMINI_TOP_K=40

# RAG Configuration
MINDNEST_RAG_N_SIMILAR_CHUNKS=10  # Number of similar code chunks to retrieve for context
MINDNEST_RAG_BATCH_SIZE=20        # Number of chunks to process in each embedding batch
MINDNEST_CONTEXT_MAX_FILES_SAME_DIR=10  # Maximum number of files to include from the same directory
MINDNEST_CONTEXT_CONTEXT_DEPTH=2        # How deep to search in directory hierarchy for code context

# GitHub Configuration
MINDNEST_GITHUB_TOKEN=your_github_personal_access_token_here
MINDNEST_GITHUB_API_URL=https://api.github.com
MINDNEST_GITHUB_REQUEST_TIMEOUT=30s
MINDNEST_GITHUB_CONCURRENCY=5   # Number of concurrent API requests

# Workspace Configuration
MINDNEST_WORKSPACE_AUTO_CREATE=true  # Automatically create a workspace for the current directory

# Database Configuration
# MINDNEST_DB_PATH=~/.mindnest/mindnest.db  # Uncomment to override default path
MINDNEST_DB_BUSY_TIMEOUT=5000  # 5 seconds
MINDNEST_DB_JOURNAL_MODE=WAL
MINDNEST_DB_SYNCHRONOUS_MODE=NORMAL  # Options: NORMAL, FULL, OFF
MINDNEST_DB_CACHE_SIZE=-64000  # 64MB
MINDNEST_DB_FOREIGN_KEYS=true  # Enable foreign key constraints
MINDNEST_DB_CONN_MAX_LIFE=5m  # 5 minutes
MINDNEST_DB_QUERY_TIMEOUT=30s  # 30 seconds

# Logging Configuration
MINDNEST_LOG_LEVEL=info  # Options: debug, info, warn, error, none
MINDNEST_LOG_FORMAT=text  # Options: text, json
# MINDNEST_LOG_OUTPUT=~/.mindnest/mindnest.log   # stdout, stderr, or file path (default)
MINDNEST_LOG_ADD_SOURCE=true
MINDNEST_LOG_TIME_FORMAT=RFC3339  # Default is RFC3339

# Server Configuration
MINDNEST_SERVER_ENABLED=true
MINDNEST_SERVER_URL=http://localhost:3000
MINDNEST_SERVER_TOKEN=your_server_token_here
MINDNEST_SERVER_TIMEOUT=30s
# MINDNEST_SERVER_DEVICE_NAME is auto-generated if not provided
# MINDNEST_SERVER_DEVICE_NAME=My CLI Instance 